{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mamba install -c pytorch -c nvidia -c conda-forge pandas spacy tqdm scikit-learn gensim sentence-transformers pytorch pytorch-cuda=12.1 -y\n",
    "! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               title  tag     artist  year   views  \\\n",
      "0          Killa Cam  rap    Cam'ron  2004  173166   \n",
      "1         Can I Live  rap      JAY-Z  1996  468624   \n",
      "2  Forgive Me Father  rap   Fabolous  2003    4743   \n",
      "3       Down and Out  rap    Cam'ron  2004  144404   \n",
      "4             Fly In  rap  Lil Wayne  2005   78271   \n",
      "\n",
      "                                       features  \\\n",
      "0                   {\"Cam\\\\'ron\",\"Opera Steve\"}   \n",
      "1                                            {}   \n",
      "2                                            {}   \n",
      "3  {\"Cam\\\\'ron\",\"Kanye West\",\"Syleena Johnson\"}   \n",
      "4                                            {}   \n",
      "\n",
      "                                              lyrics  id language_cld3  \\\n",
      "0  [Chorus: Opera Steve & Cam'ron]\\nKilla Cam, Ki...   1            en   \n",
      "1  [Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...   3            en   \n",
      "2  Maybe cause I'm eatin\\nAnd these bastards fien...   4            en   \n",
      "3  [Produced by Kanye West and Brian Miller]\\n\\n[...   5            en   \n",
      "4  [Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...   6            en   \n",
      "\n",
      "  language_ft language  \n",
      "0          en       en  \n",
      "1          en       en  \n",
      "2          en       en  \n",
      "3          en       en  \n",
      "4          en       en  \n"
     ]
    }
   ],
   "source": [
    "# Load CSV file into a pandas DataFrame, the file has a header row with the column names and the separator is a comma\n",
    "df = pd.read_csv(\"song_lyrics.csv\")\n",
    "\n",
    "# Print the first 5 rows of the dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag\n",
      "pop        2138587\n",
      "rap        1724816\n",
      "rock        793220\n",
      "rb          196462\n",
      "misc        181455\n",
      "country     100316\n",
      "Name: count, dtype: int64\n",
      "language\n",
      "en    3374198\n",
      "es     275432\n",
      "fr     189436\n",
      "pt     167947\n",
      "ru     166044\n",
      "       ...   \n",
      "mt          5\n",
      "uz          4\n",
      "tg          3\n",
      "bs          1\n",
      "gu          1\n",
      "Name: count, Length: 84, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# List the different tags in the \"tag\" column and their frequency\n",
    "print(df[\"tag\"].value_counts())\n",
    "\n",
    "# List the different languages in the \"language\" column and their frequency\n",
    "print(df[\"language\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag\n",
      "pop        1393559\n",
      "rap         964605\n",
      "rock        633308\n",
      "rb          155082\n",
      "country      86658\n",
      "Name: count, dtype: int64\n",
      "language\n",
      "en    3233212\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Eliminate rows with missing values in the \"tag\" column or with a \"misc\" tag\n",
    "df = df.dropna(subset=[\"tag\"])\n",
    "df = df[df[\"tag\"] != \"misc\"]\n",
    "\n",
    "# Eliminate rows with missing values in the \"language\" column or with a language different from \"en\"\n",
    "df = df.dropna(subset=[\"language\"])\n",
    "df = df[df[\"language\"] == \"en\"]\n",
    "\n",
    "# Print tag and language frequencies\n",
    "print(df[\"tag\"].value_counts())\n",
    "print(df[\"language\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_440312/1181091989.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"tag\").apply(lambda x: x.sample(80000), include_groups=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag\n",
      "country    80000\n",
      "pop        80000\n",
      "rap        80000\n",
      "rb         80000\n",
      "rock       80000\n",
      "Name: count, dtype: int64\n",
      "language\n",
      "en    400000\n",
      "Name: count, dtype: int64\n",
      "                                         title      tag           artist  \\\n",
      "tag                                                                        \n",
      "country 1082777                Honky Tonk Wine  country  Jerry Lee Lewis   \n",
      "        979185   If You Should Come Back Today  country    Charley Pride   \n",
      "        3433877                       Novocain  country    Jessica Meuse   \n",
      "        3394058                      Boys Girl  country     Kylie Morgan   \n",
      "        191099                     Its My Time  country     Dolly Parton   \n",
      "\n",
      "                 year  views features  \\\n",
      "tag                                     \n",
      "country 1082777  1973     62       {}   \n",
      "        979185   1968    169       {}   \n",
      "        3433877  2018     19       {}   \n",
      "        3394058  2019    274       {}   \n",
      "        191099   1969   1063       {}   \n",
      "\n",
      "                                                            lyrics       id  \\\n",
      "tag                                                                           \n",
      "country 1082777  Yeah yeah sweet sweet honky tonk wine keeps me...  1412794   \n",
      "        979185   You'd stop at hundred and forty tears I forget...  1303309   \n",
      "        3433877  [Verse 1]\\nIt’s just a relapse, it was my last...  5192852   \n",
      "        3394058  [Verse 1]\\nWhen I get married, if I ever do\\nD...  5133679   \n",
      "        191099   [Verse 1]\\nIt's my time\\nGather round girls\\nY...   207638   \n",
      "\n",
      "                language_cld3 language_ft language  \n",
      "tag                                                 \n",
      "country 1082777            en          en       en  \n",
      "        979185             en          en       en  \n",
      "        3433877            en          en       en  \n",
      "        3394058            en          en       en  \n",
      "        191099             en          en       en  \n"
     ]
    }
   ],
   "source": [
    "# Balance the dataset by keeping the same number of rows for each tag, the number of rows per tag is 80000\n",
    "df = df.groupby(\"tag\").apply(lambda x: x.sample(80000), include_groups=True)\n",
    "\n",
    "# Print tag and language frequencies\n",
    "print(df[\"tag\"].value_counts())\n",
    "print(df[\"language\"].value_counts())\n",
    "\n",
    "# Print the first 5 rows of the dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Save the balanced dataset to a new CSV file\n",
    "df.to_csv(\"lyrics_balanced.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the balanced dataset from the new CSV file if df does not exist\n",
    "if \"df\" not in locals():\n",
    "    df = pd.read_csv(\"lyrics_balanced.csv\")\n",
    "\n",
    "# Remove all lines between square brackets, including the new line character\n",
    "df[\"lyrics\"] = df[\"lyrics\"].str.replace(r\"\\[.*\\]\\n\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 399934/400000 [13:44<00:00, 659.49it/s]Process Process-9:\n",
      "Process Process-5:\n",
      "Process Process-8:\n",
      "Process Process-16:\n",
      "Process Process-13:\n",
      "Process Process-1:\n",
      "Process Process-7:\n",
      "Process Process-15:\n",
      "Process Process-12:\n",
      "Process Process-11:\n",
      "Process Process-4:\n",
      "Process Process-14:\n",
      "Process Process-2:\n",
      "Process Process-10:\n",
      "Traceback (most recent call last):\n",
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2354, in _apply_pipes\n",
      "    docs = (\n",
      "           ^\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2354, in _apply_pipes\n",
      "    docs = (\n",
      "           ^\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2354, in _apply_pipes\n",
      "    docs = (\n",
      "           ^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2354, in _apply_pipes\n",
      "    docs = (\n",
      "           ^\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2354, in _apply_pipes\n",
      "    docs = (\n",
      "           ^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2354, in _apply_pipes\n",
      "    docs = (\n",
      "           ^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2354, in _apply_pipes\n",
      "    docs = (\n",
      "           ^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2354, in _apply_pipes\n",
      "    docs = (\n",
      "           ^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2354, in _apply_pipes\n",
      "    docs = (\n",
      "           ^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2354, in _apply_pipes\n",
      "    docs = (\n",
      "           ^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2354, in _apply_pipes\n",
      "    docs = (\n",
      "           ^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2354, in _apply_pipes\n",
      "    docs = (\n",
      "           ^\n",
      "TypeError: '_WorkDoneSentinel' object is not iterable\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2354, in _apply_pipes\n",
      "    docs = (\n",
      "           ^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2354, in _apply_pipes\n",
      "    docs = (\n",
      "           ^\n",
      "TypeError: '_WorkDoneSentinel' object is not iterable\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2354, in _apply_pipes\n",
      "    docs = (\n",
      "           ^\n",
      "TypeError: '_WorkDoneSentinel' object is not iterable\n",
      "TypeError: '_WorkDoneSentinel' object is not iterable\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2354, in _apply_pipes\n",
      "    docs = (\n",
      "           ^\n",
      "TypeError: '_WorkDoneSentinel' object is not iterable\n",
      "TypeError: '_WorkDoneSentinel' object is not iterable\n",
      "TypeError: '_WorkDoneSentinel' object is not iterable\n",
      "TypeError: '_WorkDoneSentinel' object is not iterable\n",
      "TypeError: '_WorkDoneSentinel' object is not iterable\n",
      "TypeError: '_WorkDoneSentinel' object is not iterable\n",
      "TypeError: '_WorkDoneSentinel' object is not iterable\n",
      "TypeError: '_WorkDoneSentinel' object is not iterable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "TypeError: '_WorkDoneSentinel' object is not iterable\n",
      "TypeError: '_WorkDoneSentinel' object is not iterable\n",
      "TypeError: '_WorkDoneSentinel' object is not iterable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "TypeError: '_WorkDoneSentinel' object is not iterable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2367, in _apply_pipes\n",
      "    padding = [(None, None, None)] * (len(texts_with_ctx) - 1)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2367, in _apply_pipes\n",
      "    padding = [(None, None, None)] * (len(texts_with_ctx) - 1)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2367, in _apply_pipes\n",
      "    padding = [(None, None, None)] * (len(texts_with_ctx) - 1)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2367, in _apply_pipes\n",
      "    padding = [(None, None, None)] * (len(texts_with_ctx) - 1)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2367, in _apply_pipes\n",
      "    padding = [(None, None, None)] * (len(texts_with_ctx) - 1)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2367, in _apply_pipes\n",
      "    padding = [(None, None, None)] * (len(texts_with_ctx) - 1)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2367, in _apply_pipes\n",
      "    padding = [(None, None, None)] * (len(texts_with_ctx) - 1)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2367, in _apply_pipes\n",
      "    padding = [(None, None, None)] * (len(texts_with_ctx) - 1)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2367, in _apply_pipes\n",
      "    padding = [(None, None, None)] * (len(texts_with_ctx) - 1)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2367, in _apply_pipes\n",
      "    padding = [(None, None, None)] * (len(texts_with_ctx) - 1)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2367, in _apply_pipes\n",
      "    padding = [(None, None, None)] * (len(texts_with_ctx) - 1)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2367, in _apply_pipes\n",
      "    padding = [(None, None, None)] * (len(texts_with_ctx) - 1)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2367, in _apply_pipes\n",
      "    padding = [(None, None, None)] * (len(texts_with_ctx) - 1)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: object of type '_WorkDoneSentinel' has no len()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2367, in _apply_pipes\n",
      "    padding = [(None, None, None)] * (len(texts_with_ctx) - 1)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2367, in _apply_pipes\n",
      "    padding = [(None, None, None)] * (len(texts_with_ctx) - 1)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: object of type '_WorkDoneSentinel' has no len()\n",
      "TypeError: object of type '_WorkDoneSentinel' has no len()\n",
      "TypeError: object of type '_WorkDoneSentinel' has no len()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/spacy/language.py\", line 2367, in _apply_pipes\n",
      "    padding = [(None, None, None)] * (len(texts_with_ctx) - 1)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: object of type '_WorkDoneSentinel' has no len()\n",
      "TypeError: object of type '_WorkDoneSentinel' has no len()\n",
      "TypeError: object of type '_WorkDoneSentinel' has no len()\n",
      "TypeError: object of type '_WorkDoneSentinel' has no len()\n",
      "TypeError: object of type '_WorkDoneSentinel' has no len()\n",
      "TypeError: object of type '_WorkDoneSentinel' has no len()\n",
      "TypeError: object of type '_WorkDoneSentinel' has no len()\n",
      "TypeError: object of type '_WorkDoneSentinel' has no len()\n",
      "TypeError: object of type '_WorkDoneSentinel' has no len()\n",
      "TypeError: object of type '_WorkDoneSentinel' has no len()\n",
      "TypeError: object of type '_WorkDoneSentinel' has no len()\n",
      "TypeError: object of type '_WorkDoneSentinel' has no len()\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400000/400000 [13:44<00:00, 484.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           title      tag           artist  year  views  \\\n",
      "0                Honky Tonk Wine  country  Jerry Lee Lewis  1973     62   \n",
      "1  If You Should Come Back Today  country    Charley Pride  1968    169   \n",
      "2                       Novocain  country    Jessica Meuse  2018     19   \n",
      "3                      Boys Girl  country     Kylie Morgan  2019    274   \n",
      "4                    Its My Time  country     Dolly Parton  1969   1063   \n",
      "\n",
      "  features                                             lyrics       id  \\\n",
      "0       {}  Yeah yeah sweet sweet honky tonk wine keeps me...  1412794   \n",
      "1       {}  You'd stop at hundred and forty tears I forget...  1303309   \n",
      "2       {}  It’s just a relapse, it was my last time out t...  5192852   \n",
      "3       {}  When I get married, if I ever do\\nDon't give m...  5133679   \n",
      "4       {}  It's my time\\nGather round girls\\nYou I grew u...   207638   \n",
      "\n",
      "  language_cld3 language_ft language  \\\n",
      "0            en          en       en   \n",
      "1            en          en       en   \n",
      "2            en          en       en   \n",
      "3            en          en       en   \n",
      "4            en          en       en   \n",
      "\n",
      "                                        clean_lyrics  \n",
      "0  yeah yeah sweet sweet honky tonk wine keep min...  \n",
      "1  stop tear forget lonely year know lose word kn...  \n",
      "2  relapse time door mercy soul know say want say...  \n",
      "3  marry diamond lose red wine end night bother w...  \n",
      "4  time gather round girl grow old friend scuff n...  \n"
     ]
    }
   ],
   "source": [
    "# Create a spaCy pipeline for English\n",
    "nlp = spacy.load(\n",
    "    \"en_core_web_sm\",\n",
    "    enable=[\"tok2vec\", \"tagger\", \"attribute_ruler\", \"lemmatizer\"],\n",
    ")\n",
    "\n",
    "\n",
    "def preprocess_lyrics(doc):\n",
    "    return \" \".join(\n",
    "        [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    )\n",
    "\n",
    "\n",
    "# Tokenize, lemmatize, remove stopwords, and convert to lowercase in a single step\n",
    "df[\"clean_lyrics\"] = list(\n",
    "    tqdm(nlp.pipe(df[\"lyrics\"].str.lower(), batch_size=1, n_process=16), total=len(df))\n",
    ")\n",
    "\n",
    "# Apply the preprocess_lyrics function to the \"clean_lyrics\" column\n",
    "df[\"clean_lyrics\"] = df[\"clean_lyrics\"].apply(preprocess_lyrics)\n",
    "\n",
    "# Print the first 5 rows of the dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Save the cleaned dataset to a new CSV file\n",
    "df.to_csv(\"lyrics_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned dataset from the new CSV file if df does not exist\n",
    "if \"df\" not in locals():\n",
    "    df = pd.read_csv(\"lyrics_cleaned.csv\")\n",
    "\n",
    "# df = df.dropna(subset=[\"clean_lyrics\"])\n",
    "df = df.dropna(subset=[\"lyrics\"])\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     df[\"clean_lyrics\"], df[\"tag\"], test_size=0.2, random_state=42, stratify=df[\"tag\"]\n",
    "# )\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"lyrics\"], df[\"tag\"], test_size=0.2, random_state=42, stratify=df[\"tag\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319996/319996 [00:12<00:00, 25853.55it/s]\n",
      "100%|██████████| 79999/79999 [00:03<00:00, 26060.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5631570394629933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.62      0.66      0.64     16000\n",
      "         pop       0.35      0.21      0.27     16000\n",
      "         rap       0.76      0.75      0.75     16000\n",
      "          rb       0.53      0.59      0.56     16000\n",
      "        rock       0.49      0.60      0.54     15999\n",
      "\n",
      "    accuracy                           0.56     79999\n",
      "   macro avg       0.55      0.56      0.55     79999\n",
      "weighted avg       0.55      0.56      0.55     79999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF vectorizer\n",
    "# vectorizer = TfidfVectorizer()\n",
    "\n",
    "# BoW vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the training set and transform the training and testing sets, show progress bar\n",
    "X_train_vector = vectorizer.fit_transform(tqdm(X_train))\n",
    "X_test_vector = vectorizer.transform(tqdm(X_test))\n",
    "\n",
    "# Train a multinomial Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vector, y_train)\n",
    "\n",
    "# Predict the genre of the testing set\n",
    "y_pred = classifier.predict(X_test_vector)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/garcia/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5569819622745285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.62      0.68      0.65     16000\n",
      "         pop       0.34      0.31      0.32     16000\n",
      "         rap       0.78      0.72      0.75     16000\n",
      "          rb       0.56      0.54      0.55     16000\n",
      "        rock       0.49      0.54      0.51     15999\n",
      "\n",
      "    accuracy                           0.56     79999\n",
      "   macro avg       0.56      0.56      0.56     79999\n",
      "weighted avg       0.56      0.56      0.56     79999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a Logistic Regression classifier\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train_vector, y_train)\n",
    "\n",
    "# Predict the genre of the testing set\n",
    "y_pred = classifier.predict(X_test_vector)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing X_train: 100%|██████████| 319996/319996 [00:04<00:00, 74921.61it/s] \n",
      "Processing X_test: 100%|██████████| 79999/79999 [00:00<00:00, 105955.38it/s]\n",
      "Converting lyrics to embeddings: 100%|██████████| 319996/319996 [00:42<00:00, 7454.99it/s]\n",
      "Converting lyrics to embeddings: 100%|██████████| 79999/79999 [00:11<00:00, 6989.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5729696621207765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.61      0.69      0.65     16000\n",
      "         pop       0.36      0.26      0.30     16000\n",
      "         rap       0.75      0.79      0.77     16000\n",
      "          rb       0.55      0.57      0.56     16000\n",
      "        rock       0.52      0.57      0.55     15999\n",
      "\n",
      "    accuracy                           0.57     79999\n",
      "   macro avg       0.56      0.57      0.56     79999\n",
      "weighted avg       0.56      0.57      0.56     79999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the clean lyrics, showing a progress bar\n",
    "X_train_tokens = [lyrics.split() for lyrics in tqdm(X_train, desc=\"Processing X_train\")]\n",
    "X_test_tokens = [lyrics.split() for lyrics in tqdm(X_test, desc=\"Processing X_test\")]\n",
    "\n",
    "embedding_size = 300\n",
    "word2vec_model = Word2Vec(\n",
    "    sentences=X_train_tokens,\n",
    "    vector_size=embedding_size,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=16,\n",
    ")\n",
    "\n",
    "\n",
    "# Convert lyrics to word embeddings\n",
    "def lyrics_to_embeddings(lyrics_tokens, word2vec_model):\n",
    "    embeddings = []\n",
    "    for tokens in tqdm(lyrics_tokens, desc=\"Converting lyrics to embeddings\"):\n",
    "        token_embeddings = [\n",
    "            word2vec_model.wv[token] for token in tokens if token in word2vec_model.wv\n",
    "        ]\n",
    "        if len(token_embeddings) > 0:\n",
    "            embedding = np.mean(token_embeddings, axis=0)\n",
    "        else:\n",
    "            embedding = np.zeros(embedding_size)\n",
    "        embeddings.append(embedding)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "\n",
    "X_train_embeddings = lyrics_to_embeddings(X_train_tokens, word2vec_model)\n",
    "X_test_embeddings = lyrics_to_embeddings(X_test_tokens, word2vec_model)\n",
    "\n",
    "# Train a Logistic Regression classifier\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train_embeddings, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = classifier.predict(X_test_embeddings)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7b6920296d44b08be2f3578ff7d7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee75b79f344480288d624d35029c834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cuda\")\n",
    "# model = SentenceTransformer(\"avsolatorio/GIST-small-Embedding-v0\", device=\"cuda\")\n",
    "\n",
    "# Encode the clean lyrics\n",
    "X_train_embeddings = model.encode(\n",
    "    list(X_train), show_progress_bar=True, convert_to_tensor=True\n",
    ")\n",
    "X_test_embeddings = model.encode(\n",
    "    list(X_test), show_progress_bar=True, convert_to_tensor=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5703875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.59      0.68      0.63     16000\n",
      "         pop       0.37      0.26      0.30     16000\n",
      "         rap       0.75      0.78      0.77     16000\n",
      "          rb       0.55      0.58      0.56     16000\n",
      "        rock       0.52      0.55      0.54     16000\n",
      "\n",
      "    accuracy                           0.57     80000\n",
      "   macro avg       0.56      0.57      0.56     80000\n",
      "weighted avg       0.56      0.57      0.56     80000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a Logistic Regression classifier\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train_embeddings.cpu().numpy(), y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = classifier.predict(X_test_embeddings.cpu().numpy())\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
